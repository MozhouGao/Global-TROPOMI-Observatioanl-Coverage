{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32c90e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import pandas as pd \n",
    "import os \n",
    "import datetime as dt \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c471b5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def locate_file(d_str,path): \n",
    "    \"\"\"\n",
    "    function to locate TROPOMI level-2 data file based on datetime string  \n",
    "    \n",
    "    param: d_str-> datetime string (e.g., 20210101)\n",
    "    param: path -> folder path for searching TROPOMI data files\n",
    "    \n",
    "    \"\"\"\n",
    "    files=[]\n",
    "    for r, d, f in os.walk(path):\n",
    "        for file in f:\n",
    "            a = file.split('_')\n",
    "            qaue_time = a[8] \n",
    "            if d_str in qaue_time:\n",
    "                files.append(os.path.join(r, file))\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e1d88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "longitudes = np.arange(-180,180,0.1)\n",
    "latitudes = np.arange(-90,90,0.1)\n",
    "X,Y = np.meshgrid(longitudes,latitudes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64629ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rav_lon = np.ravel(X)\n",
    "rav_lat = np.ravel(Y)\n",
    "rav_lat = np.round(rav_lat,decimals=1)\n",
    "rav_lon = np.round(rav_lon,decimals=1)\n",
    "rav_lon = rav_lon.astype(str)\n",
    "rav_lat = rav_lat.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62819c1b",
   "metadata": {},
   "source": [
    "### This is an example of calculating Surface Albedo induced TOC-reducing days between 2021 and 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be7c84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"level-2 data product path\"\n",
    "\n",
    "daytime = dt.datetime(2021,1,1)\n",
    "mdf = pd.DataFrame(data={'lon':rav_lon,\n",
    "                        'lat':rav_lat,\n",
    "                        })\n",
    "\n",
    "odf1 = pd.DataFrame(data={'lon':rav_lon,\n",
    "                        'lat':rav_lat})\n",
    "while daytime.year<2022: \n",
    "    day_str = daytime.strftime(\"%Y%m%d\")\n",
    "    day_files = locate_file(day_str,path)\n",
    "    print(day_str,len(day_files))\n",
    "    i = 0 \n",
    "    for f in day_files: \n",
    "        TF = nc.Dataset(f,'r')\n",
    "        data = TF.groups['PRODUCT']\n",
    "        var = data.variables\n",
    "        SAS = data['SUPPORT_DATA']['DETAILED_RESULTS']['surface_albedo_SWIR'][0,:,:].data\n",
    "       \n",
    "        lat = var['latitude'][0,:,:].data\n",
    "        lon = var['longitude'][0,:,:].data\n",
    "\n",
    "        TF.close()\n",
    "        \n",
    "        filt = SAS == 9.96921e+36\n",
    "        SAS[filt] = -1 \n",
    "        \n",
    "        # Find grid cells with surface albedo < 0.02 \n",
    "        mask1 = (0 <= SAS) & (SAS < 0.02)  \n",
    "        \n",
    "        valid_sas = SAS[mask1]\n",
    "        valid_lat1 = lat[mask1]\n",
    "        valid_lon1 = lon[mask1]\n",
    "        \n",
    "        \n",
    "        # Find grid cells with surface albedo >= 0.02 \n",
    "        mask2 = SAS >= 0.02 \n",
    "        nd_sas = SAS[mask2]\n",
    "        nd_lat = lat[mask2]\n",
    "        nd_lon = lon[mask2]\n",
    "        \n",
    "        ones1 = np.ones(len(valid_sas))\n",
    "        ones2 = np.ones(len(nd_sas))\n",
    "                                            \n",
    "        valid_lat1 = np.round(valid_lat1,decimals=1)\n",
    "        valid_lon1 = np.round(valid_lon1,decimals=1)\n",
    "        valid_lat1  = valid_lat1.astype(str)\n",
    "        valid_lon1 = valid_lon1.astype(str)\n",
    "\n",
    "        df1 = pd.DataFrame(data={'lon':valid_lon1,\n",
    "                            'lat':valid_lat1,\n",
    "                            'sza_{}'.format(i):ones1})\n",
    "        \n",
    "        nd_lat = np.round(nd_lat,decimals=1)\n",
    "        nd_lon = np.round(nd_lon,decimals=1)\n",
    "        nd_lat  = nd_lat.astype(str)\n",
    "        nd_lon = nd_lon.astype(str)\n",
    "        df2 = pd.DataFrame(data={'lon':nd_lon,\n",
    "                            'lat':nd_lat,\n",
    "                            'sza_{}'.format(i):ones2})\n",
    "        \n",
    "        \n",
    "        \n",
    "        odf1 = pd.merge(odf1, df1, on=['lon', 'lat'],how='left')\n",
    "        odf1.drop_duplicates(inplace=True)\n",
    "        \n",
    "        mdf = pd.merge(mdf,df2,on=['lon', 'lat'],how='left')\n",
    "        mdf.drop_duplicates(inplace=True)\n",
    "        \n",
    "        i += 1 \n",
    "\n",
    "    day1 = odf1.iloc[:,2:].sum(axis=1)\n",
    "    day1 = np.array(day1)\n",
    "    \n",
    "    da = day1 > 0 \n",
    "    db = day1 <= 0 \n",
    "    day1[da] = 1 \n",
    "    day1[db] = 0 \n",
    "    \n",
    "    day_arr1 = np.reshape(day1,(1800,3600))\n",
    "    \n",
    "    \n",
    "    day2 = mdf.iloc[:,2:].sum(axis=1)\n",
    "    day2 = np.array(day2)\n",
    "    da = day2 > 0 \n",
    "    db = day2 <= 0 \n",
    "    day2[da] = 0 \n",
    "    day2[db] = 1\n",
    "    \n",
    "    day_arr2 = np.reshape(day2,(1800,3600))\n",
    "    \n",
    "    \n",
    "    TRO = nc.Dataset(r\"your path\\sas_{}.nc\".format(day_str), 'w', format='NETCDF4_CLASSIC')\n",
    "    lat = TRO.createDimension('lat', 1800)\n",
    "    lon = TRO.createDimension('lon', 3600)\n",
    "    td = TRO.createVariable('sas', int, ('lat', 'lon'))\n",
    "    td[:] = day_arr1\n",
    "    # Close File\n",
    "    TRO.close()\n",
    "    \n",
    "    TRO = nc.Dataset(r\"your path\\sas_nd_{}.nc\".format(day_str), 'w', format='NETCDF4_CLASSIC')\n",
    "    lat = TRO.createDimension('lat', 1800)\n",
    "    lon = TRO.createDimension('lon', 3600)\n",
    "    td = TRO.createVariable('sas', int, ('lat', 'lon'))\n",
    "    td[:] = day_arr2\n",
    "    # Close File\n",
    "    TRO.close()\n",
    "    \n",
    "\n",
    "    print('done output nc!')\n",
    "\n",
    "    \n",
    "    odf1 = pd.DataFrame(data={'lon':rav_lon,\n",
    "                        'lat':rav_lat})\n",
    "    \n",
    "    mdf = pd.DataFrame(data={'lon':rav_lon,\n",
    "                        'lat':rav_lat,\n",
    "                        })\n",
    "    \n",
    "    print(f\"Finished TOC-reducing day of:{daytime}\")\n",
    "    \n",
    "    daytime += dt.timedelta(days=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1f9c97",
   "metadata": {},
   "source": [
    "#### TOC-reducing days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71ebd083",
   "metadata": {},
   "outputs": [],
   "source": [
    "path  = r\"where you saved TOC-reducing days\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a412670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file list with surface albedo <= 0.02 \n",
    "files1=[]\n",
    "for r, d, f in os.walk(path):\n",
    "    for file in f:\n",
    "        if 'sas' in file:\n",
    "            files.append(os.path.join(r, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a00f5438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file list with surface albedo> 0.02 \n",
    "files2=[]\n",
    "for r, d, f in os.walk(path):\n",
    "    for file in f:\n",
    "        if 'sas' in file:\n",
    "            files2.append(os.path.join(r, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f345077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SA_day = np.empty(shape=(365,1800,3600),dtype=int)\n",
    "i = 0 \n",
    "for f in zip(files1,files2):\n",
    "    # file with surface albedo <= 0.02 \n",
    "    d1 = nc.Dataset(f[0],'r')\n",
    "    td = d1.variables['sas'][:]\n",
    "    # file with surface albedo> 0.02 \n",
    "    d2 = nc.Dataset(f[1],'r')\n",
    "    nd = d2.variables['sas'][:]\n",
    "    \n",
    "    sas = nd - td \n",
    "    \n",
    "    SA_day[i,:,:] = sas\n",
    "    d1.close()\n",
    "    d2.close()\n",
    "    i += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7957d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "saday = np.sum(SA_day,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1db7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_flip = np.flip(saday)\n",
    "saday = np.flip(sa_flip,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6175e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(saday)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
